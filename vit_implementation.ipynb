{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Develop an image classification model based on transformer architecture without relying on pre-implemented transformer or self-attention modules such as torch.nn.Transformer or torch.nn.MultiheadAttention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.config import ViTConfig, TrainingConfig, DataConfig\n",
    "from modules.ViT import VisionTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152, resnet50  # For comparison\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import asdict\n",
    "from modules.pipeline import train_and_evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data_config = DataConfig.base()\n",
    "\n",
    "# DEBUG\n",
    "# data_config.debug = True\n",
    "# data_config.batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandAugment(num_ops=2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "valset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=val_transform)\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "\n",
    "# Generate indices for splitting\n",
    "indices = list(range(len(trainset)))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Create subset datasets\n",
    "train_data = Subset(trainset, train_indices)\n",
    "val_data = Subset(valset, val_indices)\n",
    "test_data = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=val_transform)\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "if data_config.debug:\n",
    "    train_data = Subset(train_data, list(range(256)))\n",
    "    val_data = Subset(val_data, list(range(256)))\n",
    "    test_data = Subset(test_data, list(range(256)))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(\n",
    "    vit_model,\n",
    "    resnet152_model,\n",
    "    resnet50_model,\n",
    "    num_classes,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    vit_train_config: dict[str, any],\n",
    "    resnet152_train_config: dict[str, any],\n",
    "    resnet50_train_config: dict[str, any],\n",
    "    **kwargs,\n",
    "):\n",
    "\n",
    "    print(\"Evaluating ViT Model...\")\n",
    "    vit_metrics = train_and_evaluate_model(\n",
    "        vit_model, num_classes, train_loader, val_loader, test_loader, **vit_train_config\n",
    "    )\n",
    "\n",
    "    print(\"Evaluating ResNet152 Model...\")\n",
    "    resnet152_metrics = train_and_evaluate_model(\n",
    "        resnet152_model,\n",
    "        num_classes,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        **resnet152_train_config,\n",
    "    )\n",
    "\n",
    "    print(\"Evaluating ResNet Model...\")\n",
    "    resnet50_metrics = train_and_evaluate_model(\n",
    "        resnet50_model, num_classes, train_loader, val_loader, test_loader, **resnet50_train_config\n",
    "    )\n",
    "    metrics = [\n",
    "        \"Test Accuracy\",\n",
    "        \"Training Time (s)\",\n",
    "        \"Model Size\",\n",
    "        \"Avg Inference Time (s)\",\n",
    "        \"F1 Score\",\n",
    "        \"AUROC\",\n",
    "    ]\n",
    "\n",
    "    metric_keys = [\n",
    "        \"test_accuracy\",\n",
    "        \"training_time\",\n",
    "        \"model_size\",\n",
    "        \"avg_inference_time\",\n",
    "        \"test_f1\",\n",
    "        \"test_auroc\",\n",
    "    ]\n",
    "\n",
    "    # Initialize comparison dictionary with metrics\n",
    "    comparison = {\"Metric\": metrics}\n",
    "\n",
    "    # Add ViT and CNN metrics with proper length checking\n",
    "    for model_name, metrics_dict in [\n",
    "        (\"ViT\", vit_metrics),\n",
    "        (\"ResNet152\", resnet152_metrics),\n",
    "        (\"ResNet50\", resnet50_metrics),\n",
    "    ]:\n",
    "        comparison[model_name] = [metrics_dict.get(key, \"N/A\") for key in metric_keys]\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import pathlib\n",
    "\n",
    "    # print(comparison)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    pathlib.Path(f\"results/{now}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame(comparison)\n",
    "    df.to_csv(f\"results/{now}/model_comparison.csv\", index=False)\n",
    "\n",
    "    # Print comparison table\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(tabulate(df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    # Save model predictions\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ViT Predictions\": vit_metrics.get(\"test_predictions\", []),\n",
    "            \"ResNet152 Predictions\": resnet152_metrics.get(\"test_predictions\", []),\n",
    "            \"ResNet50 Predictions\": resnet50_metrics.get(\"test_predictions\", []),\n",
    "            \"Targets\": vit_metrics.get(\"test_targets\", []),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_df.to_csv(f\"results/{now}/model_predictions.csv\", index=False)\n",
    "\n",
    "    # Save Training Configs for each\n",
    "    import json\n",
    "\n",
    "    with open(f\"results/{now}/vit_train_config.json\", \"w\") as f:\n",
    "        json.dump(vit_train_config, f)\n",
    "\n",
    "    with open(f\"results/{now}/resnet152_train_config.json\", \"w\") as f:\n",
    "        json.dump(resnet152_train_config, f)\n",
    "\n",
    "    with open(f\"results/{now}/resnet50_train_config.json\", \"w\") as f:\n",
    "        json.dump(resnet50_train_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ViT Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/work/workdir/vit-assignment/.conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | VisionTransformer  | 2.7 M  | train\n",
      "1 | criterion  | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "5 | test_f1    | MulticlassF1Score  | 0      | train\n",
      "6 | test_auroc | MulticlassAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.790    Total estimated model params size (MB)\n",
      "121       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:08<00:00,  1.22it/s, v_num=16, train_loss=1.700, train_acc=0.453, val_loss=1.750, val_acc=0.434]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/workdir/vit-assignment/.conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s, v_num=16, train_loss=0.711, train_acc=0.907, val_loss=0.971, val_acc=0.814]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   avg_inference_time      0.017199436202645302\n",
      "       model_size                2697610.0\n",
      "        test_acc            0.8112999796867371\n",
      "       test_auroc           0.9727882742881775\n",
      "         test_f1            0.8101823329925537\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating ResNet152 Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | ResNet             | 58.2 M | train\n",
      "1 | criterion  | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "5 | test_f1    | MulticlassF1Score  | 0      | train\n",
      "6 | test_auroc | MulticlassAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "58.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.657   Total estimated model params size (MB)\n",
      "429       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253: 100%|██████████| 10/10 [00:11<00:00,  0.83it/s, v_num=6, train_loss=0.955, train_acc=0.792, val_loss=1.090, val_acc=0.760]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   avg_inference_time       0.02432195283472538\n",
      "       model_size               58164296.0\n",
      "        test_acc            0.7519000172615051\n",
      "       test_auroc           0.9611814618110657\n",
      "         test_f1            0.7522776126861572\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating ResNet Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | ResNet             | 23.5 M | train\n",
      "1 | criterion  | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "5 | test_f1    | MulticlassF1Score  | 0      | train\n",
      "6 | test_auroc | MulticlassAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n",
      "157       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: 100%|██████████| 10/10 [00:10<00:00,  0.95it/s, v_num=1, train_loss=0.911, train_acc=0.812, val_loss=1.030, val_acc=0.781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  7.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   avg_inference_time      0.010347764007747173\n",
      "       model_size               23528522.0\n",
      "        test_acc            0.7821000218391418\n",
      "       test_auroc           0.9699600338935852\n",
      "         test_f1            0.7799043655395508\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Model Comparison:\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|    | Metric                 |            ViT |      ResNet152 |       ResNet50 |\n",
      "+====+========================+================+================+================+\n",
      "|  0 | Test Accuracy          |    0.8113      |    0.7519      |    0.7821      |\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|  1 | Training Time (s)      | 1759.21        | 3070.81        | 1624.82        |\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|  2 | Model Size             |    2.69761e+06 |    5.81643e+07 |    2.35285e+07 |\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|  3 | Avg Inference Time (s) |    0.0171994   |    0.024322    |    0.0103478   |\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|  4 | F1 Score               |    0.810182    |    0.752278    |    0.779904    |\n",
      "+----+------------------------+----------------+----------------+----------------+\n",
      "|  5 | AUROC                  |    0.972788    |    0.961181    |    0.96996     |\n",
      "+----+------------------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "vit_config = ViTConfig.base()\n",
    "vit_model = VisionTransformer(**asdict(vit_config))\n",
    "resnet152_model = resnet152()\n",
    "resnet50_model = resnet50()\n",
    "\n",
    "vit_train_config = TrainingConfig.vit_base()\n",
    "resnet152_train_config = TrainingConfig.resnet152() \n",
    "resnet50_train_config = TrainingConfig.resnet50()  \n",
    "\n",
    "# DEBUG\n",
    "# vit_train_config.epochs = 1\n",
    "# cnn_train_config.epochs = 1\n",
    "\n",
    "compare_models(\n",
    "    vit_model,\n",
    "    resnet152_model,\n",
    "    resnet50_model,\n",
    "    data_config.num_classes,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    asdict(vit_train_config),\n",
    "    asdict(resnet152_train_config),\n",
    "    asdict(resnet50_train_config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
