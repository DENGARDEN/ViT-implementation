{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Develop an image classification model based on transformer architecture without relying on pre-implemented transformer or self-attention modules such as torch.nn.Transformer or torch.nn.MultiheadAttention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.config import ViTConfig, TrainingConfig, DataConfig\n",
    "from modules.ViT import VisionTransformer\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet152  # For comparison\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import asdict\n",
    "from modules.pipeline import train_and_evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data_config = DataConfig.base()\n",
    "\n",
    "# DEBUG\n",
    "# data_config.debug = True\n",
    "# data_config.batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandAugment(num_ops=2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "valset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=val_transform)\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "\n",
    "# Generate indices for splitting\n",
    "indices = list(range(len(trainset)))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Create subset datasets\n",
    "train_data = Subset(trainset, train_indices)\n",
    "val_data = Subset(valset, val_indices)\n",
    "test_data = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=val_transform)\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "if data_config.debug:\n",
    "    train_data = Subset(train_data, list(range(256)))\n",
    "    val_data = Subset(val_data, list(range(256)))\n",
    "    test_data = Subset(test_data, list(range(256)))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=data_config.batch_size,\n",
    "    num_workers=data_config.num_workers,\n",
    "    pin_memory=data_config.pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(\n",
    "    vit_model,\n",
    "    cnn_model,\n",
    "    num_classes,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    vit_train_config: dict[str, any],\n",
    "    cnn_train_config: dict[str, any],\n",
    "    **kwargs,\n",
    "):\n",
    "\n",
    "    print(\"Evaluating ViT Model...\")\n",
    "    vit_metrics = train_and_evaluate_model(\n",
    "        vit_model, num_classes, train_loader, val_loader, test_loader, **vit_train_config\n",
    "    )\n",
    "\n",
    "    print(\"Evaluating CNN Model...\")\n",
    "    cnn_metrics = train_and_evaluate_model(\n",
    "        cnn_model, num_classes, train_loader, val_loader, test_loader, **cnn_train_config\n",
    "    )\n",
    "    metrics = [\n",
    "        \"Test Accuracy\",\n",
    "        \"Training Time (s)\",\n",
    "        \"Model Size\",\n",
    "        \"Avg Inference Time (s)\",\n",
    "        \"F1 Score\",\n",
    "        \"AUROC\",\n",
    "    ]\n",
    "\n",
    "    metric_keys = [\n",
    "        \"test_accuracy\",\n",
    "        \"training_time\",\n",
    "        \"model_size\",\n",
    "        \"avg_inference_time\",\n",
    "        \"test_f1\",\n",
    "        \"test_auroc\",\n",
    "    ]\n",
    "\n",
    "    # Initialize comparison dictionary with metrics\n",
    "    comparison = {\"Metric\": metrics}\n",
    "\n",
    "    # Add ViT and CNN metrics with proper length checking\n",
    "    for model_name, metrics_dict in [(\"ViT\", vit_metrics), (\"CNN\", cnn_metrics)]:\n",
    "        comparison[model_name] = [metrics_dict.get(key, \"N/A\") for key in metric_keys]\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    import pathlib\n",
    "\n",
    "    # print(comparison)\n",
    "    now = datetime.now().srtftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    pathlib.Path(f\"results/{now}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame(comparison)\n",
    "    df.to_csv(f\"results/{now}/model_comparison.csv\", index=False)\n",
    "\n",
    "    # Print comparison table\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(tabulate(df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    # Save model predictions\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ViT Predictions\": vit_metrics.get(\"test_predictions\", []),\n",
    "            \"CNN Predictions\": cnn_metrics.get(\"test_predictions\", []),\n",
    "            \"Targets\": vit_metrics.get(\"test_targets\", []),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_df.to_csv(f\"results/{now}/model_predictions.csv\", index=False)\n",
    "\n",
    "    # Save Training Configs for each\n",
    "    import json\n",
    "\n",
    "    with open(f\"results/{now}/vit_train_config.json\", \"w\") as f:\n",
    "        json.dump(vit_train_config, f)\n",
    "\n",
    "    with open(f\"results/{now}/cnn_train_config.json\", \"w\") as f:\n",
    "        json.dump(cnn_train_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ViT Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | VisionTransformer  | 2.7 M  | train\n",
      "1 | criterion  | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "5 | test_f1    | MulticlassF1Score  | 0      | train\n",
      "6 | test_auroc | MulticlassAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.790    Total estimated model params size (MB)\n",
      "121       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 157/157 [00:06<00:00, 24.01it/s, v_num=7, train_loss=1.670, train_acc=0.469, val_loss=1.200, val_acc=0.684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/workdir/vit-assignment/.conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 157/157 [00:07<00:00, 22.32it/s, v_num=7, train_loss=0.833, train_acc=0.844, val_loss=0.895, val_acc=0.834]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:02<00:00, 17.14it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   avg_inference_time      0.006124526262283325\n",
      "       model_size                2697610.0\n",
      "        test_acc             0.833299994468689\n",
      "       test_auroc           0.9820541739463806\n",
      "         test_f1            0.8342033624649048\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CNN Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | ResNet             | 58.2 M | train\n",
      "1 | criterion  | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "5 | test_f1    | MulticlassF1Score  | 0      | train\n",
      "6 | test_auroc | MulticlassAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "58.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.657   Total estimated model params size (MB)\n",
      "429       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 157/157 [00:14<00:00, 10.66it/s, v_num=0, train_loss=2.080, train_acc=0.250, val_loss=7.280, val_acc=0.268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:03<00:00, 12.19it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   avg_inference_time      0.021277153864502907\n",
      "       model_size               58164296.0\n",
      "        test_acc            0.2685000002384186\n",
      "       test_auroc            0.728996217250824\n",
      "         test_f1            0.2315855622291565\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "{'Metric': ['Test Accuracy', 'Training Time (s)', 'Model Size', 'Avg Inference Time (s)', 'F1 Score', 'AUROC'], 'ViT': [0.833299994468689, 542.2475743638352, 2697610, 0.006124526262283325, 0.8342033624649048, 0.9820541739463806], 'CNN': [0.2685000002384186, 497.98931500688195, 58164298, 0.02127715349197388, 0.2315855622291565, 0.728996217250824]}\n",
      "\n",
      "Model Comparison:\n",
      "+----+------------------------+---------------+---------------+\n",
      "|    | Metric                 |           ViT |           CNN |\n",
      "+====+========================+===============+===============+\n",
      "|  0 | Test Accuracy          |   0.8333      |   0.2685      |\n",
      "+----+------------------------+---------------+---------------+\n",
      "|  1 | Training Time (s)      | 542.248       | 497.989       |\n",
      "+----+------------------------+---------------+---------------+\n",
      "|  2 | Model Size             |   2.69761e+06 |   5.81643e+07 |\n",
      "+----+------------------------+---------------+---------------+\n",
      "|  3 | Avg Inference Time (s) |   0.00612453  |   0.0212772   |\n",
      "+----+------------------------+---------------+---------------+\n",
      "|  4 | F1 Score               |   0.834203    |   0.231586    |\n",
      "+----+------------------------+---------------+---------------+\n",
      "|  5 | AUROC                  |   0.982054    |   0.728996    |\n",
      "+----+------------------------+---------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "vit_config = ViTConfig.base()\n",
    "vit_model = VisionTransformer(**asdict(vit_config))\n",
    "cnn_model = resnet152()\n",
    "\n",
    "vit_train_config = TrainingConfig.vit_base()\n",
    "cnn_train_config = TrainingConfig.resnet152()\n",
    "\n",
    "# DEBUG\n",
    "# vit_train_config.epochs = 1\n",
    "# cnn_train_config.epochs = 1\n",
    "\n",
    "compare_models(\n",
    "    vit_model,\n",
    "    cnn_model,\n",
    "    data_config.num_classes,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    asdict(vit_train_config),\n",
    "    asdict(cnn_train_config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
